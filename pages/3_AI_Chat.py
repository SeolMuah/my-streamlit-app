import streamlit as st
import os
from google import genai
from google.genai import types

st.set_page_config(page_title="AI ì±„íŒ…", page_icon="ğŸ’¬", layout="wide")

st.title("ğŸ’¬ AI ìœ ì§€ë³´ìˆ˜ ë„ìš°ë¯¸")
st.markdown("---")

# API í‚¤ í™•ì¸
api_key = st.secrets.get("GEMINI_API_KEY", None)

if not api_key:
    st.warning("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.info("""
    ì„¤ì • ë°©ë²•:
    1. `.streamlit/secrets.toml` íŒŒì¼ ìƒì„±
    2. ë‹¤ìŒ ë‚´ìš© ì¶”ê°€:
    ```
    GEMINI_API_KEY = "your-api-key-here"
    ```
    """)
else:
    # Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = genai.Client(api_key=api_key)
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # ì±„íŒ… ì„¤ì •
    generation_config = types.GenerateContentConfig(
        temperature=0.7,
        top_p=0.9,
        top_k=40,
        max_output_tokens=500,
        system_instruction="""ë„ˆëŠ” ìœ ì•• ì‹œìŠ¤í…œ ì „ë¬¸ê°€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. 
        ì‚¬ìš©ìê°€ ìœ ì•• ì‹œìŠ¤í…œì˜ ì´ìƒ ì§•í›„, ìœ ì§€ë³´ìˆ˜, ë¬¸ì œ í•´ê²°ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´ 
        ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•´. 
        ë¶€í’ˆ: ëƒ‰ê°ê¸°(Cooler), ë°¸ë¸Œ(Valve), íŒí”„(Pump), ìœ ì••(Hydraulic)
        ì„¼ì„œ: ì••ë ¥(PS), ì˜¨ë„(TS), ìœ ëŸ‰(FS), ì§„ë™(VS), ì „ë ¥(EPS)"""
    )
    
    # AI ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (ì¤‘ë³µ ì½”ë“œë¥¼ ì¤„ì´ê¸° ìœ„í•´ í•¨ìˆ˜ë¡œ ë¶„ë¦¬)
    def generate_ai_response():
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ Gemini í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            messages = []
            for msg in st.session_state.chat_history:
                if msg["role"] == "user":
                    messages.append({"role": "user", "parts": [{"text": msg["content"]}]})
                else:
                    messages.append({"role": "model", "parts": [{"text": msg["content"]}]})
            
            # ì‘ë‹µ ìƒì„±
            response = client.models.generate_content(
                model="gemini-2.0-flash-exp",
                contents=messages,
                config=generation_config
            )
            
            # AI ì‘ë‹µ í‘œì‹œ
            assistant_response = response.text
            st.session_state.chat_history.append({"role": "assistant", "content": assistant_response})
            # ì‘ë‹µì´ í‘œì‹œë˜ë„ë¡ í™”ë©´ì„ ë‹¤ì‹œ ê·¸ë¦½ë‹ˆë‹¤.
            st.rerun() 
            
        except Exception as e:
            st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ì±„íŒ… ì„¤ì •")
        
        # ì˜ˆì‹œ ì§ˆë¬¸
        st.subheader("ì˜ˆì‹œ ì§ˆë¬¸")
        example_questions = [
            "íŒí”„ì—ì„œ ì´ìƒì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
            "ëƒ‰ê°ê¸° íš¨ìœ¨ì´ ë–¨ì–´ì¡Œì„ ë•Œ ì ê²€ ì‚¬í•­ì€?",
            "ì••ë ¥ ì„¼ì„œ ê°’ì´ ë¹„ì •ìƒì ìœ¼ë¡œ ë†’ìŠµë‹ˆë‹¤.",
            "ì˜ˆë°©ì  ìœ ì§€ë³´ìˆ˜ ì¼ì •ì€ ì–´ë–»ê²Œ ìˆ˜ë¦½í•˜ë‚˜ìš”?"
        ]
        
        for q in example_questions:
            if st.button(q, key=f"ex_{q}"):
                st.session_state.chat_history.append({"role": "user", "content": q})
                generate_ai_response() # ë²„íŠ¼ í´ë¦­ ì‹œ AI ì‘ë‹µ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
        
        # ëŒ€í™” ì´ˆê¸°í™”
        if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.chat_history = []
            st.rerun()
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    st.subheader("ëŒ€í™”")
    
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.chat_history:
        if message["role"] == "user":
            st.chat_message("user").write(message["content"])
        else:
            st.chat_message("assistant").write(message["content"])
    
    # ì…ë ¥ì°½
    if prompt := st.chat_input("ìœ ì•• ì‹œìŠ¤í…œì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        generate_ai_response() # ì…ë ¥ì°½ì— ì…ë ¥ ì‹œ AI ì‘ë‹µ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ