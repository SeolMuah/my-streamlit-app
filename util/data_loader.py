import streamlit as st
import pandas as pd
import numpy as np
import pickle
import json
import os
import time
from scipy.stats import skew, kurtosis
import warnings
warnings.filterwarnings('ignore')

# ì„¼ì„œë³„ ì£¼íŒŒìˆ˜ ì •ë³´
SENSOR_FREQUENCIES = {
    'PS1': 100, 'PS2': 100, 'PS3': 100, 'PS4': 100, 'PS5': 100, 'PS6': 100,
    'EPS1': 100,
    'FS1': 10, 'FS2': 10,
    'TS1': 1, 'TS2': 1, 'TS3': 1, 'TS4': 1,
    'VS1': 1,
    'CE': 1, 'CP': 1, 'SE': 1
}

def get_sensor_time_axis(sensor_name, cycle_duration=60):
    """ì„¼ì„œë³„ ì‹œê°„ì¶• ìƒì„± (60ì´ˆ ê¸°ì¤€)"""
    freq = SENSOR_FREQUENCIES.get(sensor_name, 1)
    num_samples = freq * cycle_duration
    return np.linspace(0, cycle_duration, num_samples)

# HydraulicDataLoader í´ë˜ìŠ¤
class HydraulicDataLoader:
    def __init__(self, data_folder_path, window_seconds=10, stride_seconds=10):
        self.data_folder_path = data_folder_path
        self.window_seconds = window_seconds
        self.stride_seconds = stride_seconds
        
        # ì„¼ì„œ ì •ë³´ (SENSOR_FREQUENCIESì™€ ë™ì¼)
        self.sensor_info = {
            'PS1': {'freq': 100, 'type': 'pressure'},
            'PS2': {'freq': 100, 'type': 'pressure'},
            'PS3': {'freq': 100, 'type': 'pressure'},
            'PS4': {'freq': 100, 'type': 'pressure'},
            'PS5': {'freq': 100, 'type': 'pressure'},
            'PS6': {'freq': 100, 'type': 'pressure'},
            'EPS1': {'freq': 100, 'type': 'motor_power'},
            'FS1': {'freq': 10, 'type': 'flow'},
            'FS2': {'freq': 10, 'type': 'flow'},
            'TS1': {'freq': 1, 'type': 'temperature'},
            'TS2': {'freq': 1, 'type': 'temperature'},
            'TS3': {'freq': 1, 'type': 'temperature'},
            'TS4': {'freq': 1, 'type': 'temperature'},
            'VS1': {'freq': 1, 'type': 'vibration'},
            'CE': {'freq': 1, 'type': 'cooling_efficiency'},
            'CP': {'freq': 1, 'type': 'cooling_power'},
            'SE': {'freq': 1, 'type': 'efficiency_factor'}
        }
        
        self.sensor_data = {}
        self.profile_data = None
        self.current_cycle_index = 0
        self.num_cycles = 0

    def _load_all_data(self):
        """ëª¨ë“  ì„¼ì„œ ë°ì´í„°ì™€ í”„ë¡œíŒŒì¼ ë¡œë“œ"""
        with st.spinner("ë°ì´í„° ë¡œë“œ ì¤‘..."):
            progress_text = "ì„¼ì„œ ë°ì´í„° íŒŒì¼ ì½ëŠ” ì¤‘. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”."
            my_bar = st.progress(0, text=progress_text)
            
            if not os.path.exists(self.data_folder_path):
                st.error(f"ê²½ê³ : ë°ì´í„° í´ë” '{self.data_folder_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                self._generate_dummy_data()
                my_bar.empty()
                return
            
            try:
                # ì„¼ì„œ ë°ì´í„° ë¡œë“œ
                all_files_found = True
                sensor_names = list(self.sensor_info.keys())
                
                for i, sensor_name in enumerate(sensor_names):
                    file_path = os.path.join(self.data_folder_path, f"{sensor_name}.txt")
                    
                    my_bar.progress(int(((i + 1) / len(sensor_names)) * 80), 
                                   text=f"{sensor_name}.txt ë¡œë“œ ì¤‘...")
                    
                    if os.path.exists(file_path):
                        data = pd.read_csv(file_path, sep='\t', header=None)
                        self.sensor_data[sensor_name] = data
                    else:
                        st.warning(f"ì„¼ì„œ '{sensor_name}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        all_files_found = False
                        break
                
                # í”„ë¡œíŒŒì¼ ë°ì´í„° ë¡œë“œ
                profile_path = os.path.join(self.data_folder_path, 'profile.txt')
                if os.path.exists(profile_path):
                    my_bar.progress(90, text="í”„ë¡œíŒŒì¼ ë°ì´í„° ë¡œë“œ ì¤‘...")
                    self.profile_data = pd.read_csv(
                        profile_path, 
                        sep='\t', 
                        header=None,
                        names=['cooler', 'valve', 'pump', 'hydraulic', 'stable']
                    )
                    self.num_cycles = len(self.profile_data)
                    my_bar.progress(100, text="ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
                else:
                    st.warning("í”„ë¡œíŒŒì¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    all_files_found = False
                
                my_bar.empty()
                
                if not all_files_found or len(self.sensor_data) == 0:
                    self._generate_dummy_data()
                    st.warning("ì‹¤ì œ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                else:
                    st.success(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ì´ {self.num_cycles}ê°œ ì‚¬ì´í´")
                    
            except Exception as e:
                st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                my_bar.empty()
                self._generate_dummy_data()

    def _generate_dummy_data(self):
        """ë”ë¯¸ ë°ì´í„° ìƒì„±"""
        self.num_cycles = 100
        
        # ê° ì„¼ì„œë³„ ë”ë¯¸ ë°ì´í„° ìƒì„±
        for sensor_name, info in self.sensor_info.items():
            freq = info['freq']
            cycle_length = freq * 60  # 60ì´ˆ ì‚¬ì´í´
            
            # ì„¼ì„œ íƒ€ì…ë³„ ê¸°ë³¸ê°’ ì„¤ì •
            if sensor_name.startswith('PS'):
                base_value = np.random.uniform(140, 160)
            elif sensor_name.startswith('TS'):
                base_value = np.random.uniform(35, 40)
            elif sensor_name.startswith('FS'):
                base_value = np.random.uniform(8, 12)
            elif sensor_name == 'EPS1':
                base_value = np.random.uniform(2000, 2500)
            elif sensor_name == 'VS1':
                base_value = np.random.uniform(0.5, 1.0)
            else:  # CE, CP, SE
                base_value = np.random.uniform(0.8, 1.2)
            
            # ì‚¬ì´í´ë³„ ë°ì´í„° ìƒì„±
            dummy_data = []
            for cycle in range(self.num_cycles):
                cycle_data = base_value + np.random.normal(0, base_value * 0.03, cycle_length)
                dummy_data.append(cycle_data)
            
            self.sensor_data[sensor_name] = pd.DataFrame(dummy_data)
        
        # ë”ë¯¸ í”„ë¡œíŒŒì¼ ë°ì´í„° ìƒì„±
        self.profile_data = pd.DataFrame({
            'cooler': np.random.choice([3, 20, 100], self.num_cycles, p=[0.1, 0.2, 0.7]),
            'valve': np.random.choice([73, 80, 90, 100], self.num_cycles, p=[0.1, 0.1, 0.2, 0.6]),
            'pump': np.random.choice([0, 1, 2], self.num_cycles, p=[0.7, 0.2, 0.1]),
            'hydraulic': np.random.choice([90, 100, 115, 130], self.num_cycles, p=[0.1, 0.1, 0.2, 0.6]),
            'stable': np.ones(self.num_cycles, dtype=int)
        })

    def get_next_window(self):
        """ë‹¤ìŒ 10ì´ˆ ìœˆë„ìš° ë°ì´í„° ë°˜í™˜"""
        if self.num_cycles == 0:
            return None, None
        
        if self.current_cycle_index >= self.num_cycles:
            self.current_cycle_index = 0
        
        # í˜„ì¬ ì‚¬ì´í´ì—ì„œ ëœë¤í•˜ê²Œ ìœˆë„ìš° ì‹œì‘ ìœ„ì¹˜ ì„ íƒ
        cycle_idx = self.current_cycle_index
        window_start = np.random.choice([0, 10, 20, 30, 40, 50])  # 0~50ì´ˆ ì¤‘ í•˜ë‚˜
        window_end = window_start + self.window_seconds
        
        window_data = {}
        
        # ê° ì„¼ì„œì˜ ìœˆë„ìš° ë°ì´í„° ì¶”ì¶œ
        for sensor_name, sensor_df in self.sensor_data.items():
            freq = self.sensor_info[sensor_name]['freq']
            
            start_idx = int(window_start * freq)
            end_idx = int(window_end * freq)
            
            # í•´ë‹¹ ì‚¬ì´í´ì˜ ì„¼ì„œ ë°ì´í„°
            cycle_data = sensor_df.iloc[cycle_idx].values
            window_samples = cycle_data[start_idx:end_idx]
            
            window_data[sensor_name] = window_samples
        
        # í•´ë‹¹ ì‚¬ì´í´ì˜ ë¼ë²¨ ì •ë³´
        cycle_labels = self.profile_data.iloc[cycle_idx] if self.profile_data is not None else None
        
        self.current_cycle_index += 1
        
# íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
def extract_features_from_window(window_data):
    """ìœˆë„ìš° ë°ì´í„°ì—ì„œ íŠ¹ì§• ì¶”ì¶œ (NaN ì²˜ë¦¬ ê°•í™”)"""
    features = {}
    
    for sensor_name, sensor_values in window_data.items():
        values = np.array(sensor_values)
        
        # ìœ íš¨í•œ ê°’ë§Œ ì„ íƒ (NaN, inf ì œê±°)
        valid_values = values[np.isfinite(values)]
        
        if len(valid_values) < 2:
            # ìœ íš¨í•œ ê°’ì´ ë¶€ì¡±í•œ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
            features[f'{sensor_name}_mean'] = 0.0
            features[f'{sensor_name}_std'] = 0.0
            features[f'{sensor_name}_max'] = 0.0
            features[f'{sensor_name}_min'] = 0.0
            features[f'{sensor_name}_rms'] = 0.0
            features[f'{sensor_name}_peak2peak'] = 0.0
            features[f'{sensor_name}_skew'] = 0.0
            features[f'{sensor_name}_kurtosis'] = 0.0
            continue
        
        # ê¸°ë³¸ í†µê³„ íŠ¹ì§•
        try:
            features[f'{sensor_name}_mean'] = np.mean(valid_values)
        except:
            features[f'{sensor_name}_mean'] = 0.0
            
        try:
            features[f'{sensor_name}_std'] = np.std(valid_values)
        except:
            features[f'{sensor_name}_std'] = 0.0
            
        try:
            features[f'{sensor_name}_max'] = np.max(valid_values)
        except:
            features[f'{sensor_name}_max'] = 0.0
            
        try:
            features[f'{sensor_name}_min'] = np.min(valid_values)
        except:
            features[f'{sensor_name}_min'] = 0.0
            
        try:
            features[f'{sensor_name}_rms'] = np.sqrt(np.mean(valid_values**2))
        except:
            features[f'{sensor_name}_rms'] = 0.0
            
        try:
            features[f'{sensor_name}_peak2peak'] = np.max(valid_values) - np.min(valid_values)
        except:
            features[f'{sensor_name}_peak2peak'] = 0.0
            
        # ê³ ì°¨ í†µê³„ íŠ¹ì§•
        try:
            if len(valid_values) > 2:
                from scipy.stats import skew, kurtosis
                skew_val = skew(valid_values)
                features[f'{sensor_name}_skew'] = skew_val if np.isfinite(skew_val) else 0.0
            else:
                features[f'{sensor_name}_skew'] = 0.0
        except:
            features[f'{sensor_name}_skew'] = 0.0
            
        try:
            if len(valid_values) > 2:
                from scipy.stats import skew, kurtosis
                kurt_val = kurtosis(valid_values)
                features[f'{sensor_name}_kurtosis'] = kurt_val if np.isfinite(kurt_val) else 0.0
            else:
                features[f'{sensor_name}_kurtosis'] = 0.0
        except:
            features[f'{sensor_name}_kurtosis'] = 0.0
    
    return features

# ì´ìƒ íƒì§€ í•¨ìˆ˜
def detect_anomaly(features, models, scalers, metadata):
    """ê° ë¶€í’ˆë³„ ì´ìƒ íƒì§€ (NaN ì²˜ë¦¬ ê°•í™”)"""
    # DataFrame ìƒì„±
    features_df = pd.DataFrame([features])
    
    # metadataì—ì„œ feature_columns ê°€ì ¸ì˜¤ê¸°
    feature_cols = metadata.get('feature_columns', [])
    
    # í•„ìš”í•œ íŠ¹ì§•ë§Œ ì„ íƒí•˜ê³  ëˆ„ë½ëœ íŠ¹ì§•ì€ 0ìœ¼ë¡œ ì±„ì›€
    features_selected = features_df.reindex(columns=feature_cols, fill_value=0.0)
    
    # NaN ê°’ì„ 0ìœ¼ë¡œ ëŒ€ì²´
    features_selected = features_selected.fillna(0.0)
    
    # inf ê°’ë„ ì²˜ë¦¬
    features_selected = features_selected.replace([np.inf, -np.inf], 0.0)
    
    # ìµœì¢… ê²€ì¦: ì—¬ì „íˆ NaNì´ ìˆëŠ”ì§€ í™•ì¸
    if features_selected.isnull().any().any():
        st.warning("íŠ¹ì§• ë°ì´í„°ì— ì—¬ì „íˆ NaN ê°’ì´ ìˆìŠµë‹ˆë‹¤. ëª¨ë“  NaNì„ 0ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        features_selected = features_selected.fillna(0.0)
    
    results = {}
    
    for comp_name in ['cooler', 'valve', 'pump', 'hydraulic']:
        try:
            # ìŠ¤ì¼€ì¼ë§ ì „ ë°ì´í„° ê²€ì¦
            X_input = features_selected.copy()
            
            # ìŠ¤ì¼€ì¼ë§
            X_scaled = scalers[comp_name].transform(X_input)
            
            # ìŠ¤ì¼€ì¼ë§ í›„ì—ë„ NaN ì²´í¬
            if np.any(np.isnan(X_scaled)) or np.any(np.isinf(X_scaled)):
                st.warning(f"{comp_name} ìŠ¤ì¼€ì¼ë§ í›„ NaN/inf ê°’ ë°œê²¬. 0ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0)
            
            # ì˜ˆì¸¡
            prediction = models[comp_name].predict(X_scaled)[0]
            score = models[comp_name].decision_function(X_scaled)[0]
            
            # ì ìˆ˜ê°€ NaNì¸ ê²½ìš° ì²˜ë¦¬
            if np.isnan(score) or np.isinf(score):
                score = 0.0
            
            results[comp_name] = {
                'is_anomaly': prediction == -1,
                'score': float(score),
                'confidence': abs(float(score))
            }
            
        except Exception as e:
            st.error(f"{comp_name} ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
            results[comp_name] = {
                'is_anomaly': False,
                'score': 0.0,
                'confidence': 0.0
            }
    
    return results

def generate_dummy_sensor_data():
    """ë”ë¯¸ ì„¼ì„œ ë°ì´í„° ìƒì„±"""
    sensor_list = ['PS1', 'PS2', 'PS3', 'PS4', 'PS5', 'PS6', 'EPS1']
    sensor_data = {}
    
    for sensor in sensor_list:
        # 100ê°œ ì‚¬ì´í´, ê° ì‚¬ì´í´ë‹¹ ì£¼íŒŒìˆ˜ì— ë”°ë¥¸ ë°ì´í„° í¬ì¸íŠ¸
        num_cycles = 100
        freq = SENSOR_FREQUENCIES.get(sensor, 100)
        cycle_length = freq * 60  # 60ì´ˆ ì‚¬ì´í´
        
        # ì„¼ì„œ íƒ€ì…ë³„ ê¸°ë³¸ê°’ ì„¤ì •
        if sensor.startswith('PS'):
            base_value = np.random.uniform(140, 160)
        elif sensor == 'EPS1':
            base_value = np.random.uniform(2000, 2500)
        else:
            base_value = np.random.uniform(35, 40)
        
        # ì‚¬ì´í´ë³„ ë°ì´í„° ìƒì„±
        dummy_data = []
        for cycle in range(num_cycles):
            cycle_data = base_value + np.random.normal(0, base_value * 0.03, cycle_length)
            dummy_data.append(cycle_data)
        
        sensor_data[sensor] = pd.DataFrame(dummy_data)
    
    return sensor_data

def generate_dummy_labels():
    """ë”ë¯¸ ë¼ë²¨ ë°ì´í„° ìƒì„±"""
    num_cycles = 100
    
    labels = pd.DataFrame({
        'cooler': np.random.choice([3, 20, 100], num_cycles, p=[0.1, 0.2, 0.7]),
        'valve': np.random.choice([73, 80, 90, 100], num_cycles, p=[0.1, 0.1, 0.2, 0.6]),
        'pump': np.random.choice([0, 1, 2], num_cycles, p=[0.7, 0.2, 0.1]),
        'hydraulic': np.random.choice([90, 100, 115, 130], num_cycles, p=[0.1, 0.1, 0.2, 0.6]),
        'stable': np.ones(num_cycles, dtype=int)
    })
    
    return labels

# ë°ì´í„° ë¡œë” ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ìºì‹œë¨)
@st.cache_resource(ttl=3600)
def get_data_loader(data_folder_path='data'):
    """ë°ì´í„° ë¡œë” ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ìºì‹œë¨)"""
    loader = HydraulicDataLoader(data_folder_path)
    loader._load_all_data()
    return loader

# ì„¼ì„œë³„ ì£¼íŒŒìˆ˜ ì •ë³´
SENSOR_FREQUENCIES = {
    'PS1': 100, 'PS2': 100, 'PS3': 100, 'PS4': 100, 'PS5': 100, 'PS6': 100,
    'EPS1': 100,
    'FS1': 10, 'FS2': 10,
    'TS1': 1, 'TS2': 1, 'TS3': 1, 'TS4': 1,
    'VS1': 1,
    'CE': 1, 'CP': 1, 'SE': 1
}

def get_sensor_time_axis(sensor_name, cycle_duration=60):
    """ì„¼ì„œë³„ ì‹œê°„ì¶• ìƒì„± (60ì´ˆ ê¸°ì¤€)"""
    freq = SENSOR_FREQUENCIES.get(sensor_name, 1)
    num_samples = freq * cycle_duration
    return np.linspace(0, cycle_duration, num_samples)
    

# ìºì‹œëœ ë°ì´í„° ë¡œë” í•¨ìˆ˜ë“¤
@st.cache_data(ttl=3600)  # 1ì‹œê°„ ë™ì•ˆ ìºì‹œ
def load_sensor_data(data_folder_path='data', show_progress=True):
    """ì„¼ì„œ ë°ì´í„° ë¡œë“œ (ìºì‹œë¨)"""
    sensor_list = ['PS1', 'PS2', 'PS3', 'PS4', 'PS5', 'PS6', 'EPS1', 
                   'FS1', 'FS2', 'TS1', 'TS2', 'TS3', 'TS4', 'VS1', 
                   'CE', 'CP', 'SE']
    
    sensor_data = {}
    
    if show_progress:
        progress_text = "ì„¼ì„œ ë°ì´í„° íŒŒì¼ì„ í™•ì¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."
        progress_bar = st.progress(0, text=progress_text)
        status_placeholder = st.empty()
        
        total_sensors = len(sensor_list)
        loaded_count = 0
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        existing_files = []
        for sensor in sensor_list:
            file_path = os.path.join(data_folder_path, f'{sensor}.txt')
            if os.path.exists(file_path):
                existing_files.append(sensor)
        
        if not existing_files:
            progress_bar.progress(100, text="ì‹¤ì œ íŒŒì¼ì´ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            status_placeholder.warning("ğŸ“ ì‹¤ì œ ì„¼ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            time.sleep(1)
            sensor_data = generate_dummy_sensor_data()
            progress_bar.empty()
            status_placeholder.empty()
            return sensor_data
        
        # íŒŒì¼ ë¡œë”©
        for i, sensor in enumerate(existing_files):
            file_path = os.path.join(data_folder_path, f'{sensor}.txt')
            
            progress_percent = int((i / len(existing_files)) * 100)
            progress_bar.progress(progress_percent, text=f"ğŸ“Š {sensor}.txt íŒŒì¼ ë¡œë”© ì¤‘... ({i+1}/{len(existing_files)})")
            
            try:
                with status_placeholder.container():
                    st.info(f"ğŸ”„ {sensor}.txt íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
                
                data = pd.read_csv(file_path, sep='\t', header=None)
                sensor_data[sensor] = data
                loaded_count += 1
                
                with status_placeholder.container():
                    st.success(f"âœ… {sensor}.txt íŒŒì¼ ë¡œë“œ ì™„ë£Œ! ({len(data)} í–‰)")
                
                time.sleep(0.1)  # ì‚¬ìš©ìê°€ ë³¼ ìˆ˜ ìˆë„ë¡ ì ì‹œ ëŒ€ê¸°
                
            except Exception as e:
                with status_placeholder.container():
                    st.error(f"âŒ {sensor}.txt íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                time.sleep(0.5)
        
        progress_bar.progress(100, text=f"âœ… ì„¼ì„œ ë°ì´í„° ë¡œë”© ì™„ë£Œ! ({loaded_count}/{len(existing_files)} íŒŒì¼)")
        
        if loaded_count == 0:
            status_placeholder.warning("ì‹¤ì œ ì„¼ì„œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            sensor_data = generate_dummy_sensor_data()
        else:
            status_placeholder.success(f"ğŸ‰ ì´ {loaded_count}ê°œì˜ ì„¼ì„œ ë°ì´í„° íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        time.sleep(1)
        progress_bar.empty()
        status_placeholder.empty()
        
    else:
        # ì§„í–‰ ìƒí™© í‘œì‹œ ì—†ì´ ë¡œë“œ (ê¸°ì¡´ ë°©ì‹)
        for sensor in sensor_list:
            file_path = os.path.join(data_folder_path, f'{sensor}.txt')
            if os.path.exists(file_path):
                try:
                    data = pd.read_csv(file_path, sep='\t', header=None)
                    sensor_data[sensor] = data
                except Exception as e:
                    st.warning(f"ì„¼ì„œ {sensor} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        if not sensor_data:
            sensor_data = generate_dummy_sensor_data()
    
    return sensor_data

@st.cache_data(ttl=3600)  # 1ì‹œê°„ ë™ì•ˆ ìºì‹œ
def load_labels(data_folder_path='data', show_progress=True):
    """ë¼ë²¨ ë°ì´í„° ë¡œë“œ (ìºì‹œë¨)"""
    profile_path = os.path.join(data_folder_path, 'profile.txt')
    
    if show_progress:
        progress_bar = st.progress(0, text="ë¼ë²¨ ë°ì´í„° íŒŒì¼ì„ í™•ì¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
        status_placeholder = st.empty()
        
        if os.path.exists(profile_path):
            try:
                progress_bar.progress(25, text="ğŸ“‹ profile.txt íŒŒì¼ í™•ì¸ ì™„ë£Œ")
                status_placeholder.info("ğŸ”„ profile.txt íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
                time.sleep(0.2)
                
                progress_bar.progress(50, text="ğŸ“‹ profile.txt íŒŒì¼ ì½ëŠ” ì¤‘...")
                labels = pd.read_csv(profile_path, sep='\t', header=None,
                                   names=['cooler', 'valve', 'pump', 'hydraulic', 'stable'])
                
                progress_bar.progress(75, text="ğŸ“‹ ë¼ë²¨ ë°ì´í„° ê²€ì¦ ì¤‘...")
                status_placeholder.success(f"âœ… profile.txt íŒŒì¼ ë¡œë“œ ì™„ë£Œ! ({len(labels)} ë¼ë²¨)")
                time.sleep(0.2)
                
                progress_bar.progress(100, text="âœ… ë¼ë²¨ ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
                time.sleep(0.5)
                
                progress_bar.empty()
                status_placeholder.empty()
                
                return labels
                
            except Exception as e:
                progress_bar.progress(100, text="âŒ ë¼ë²¨ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                status_placeholder.error(f"âŒ profile.txt íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                time.sleep(1)
                
                progress_bar.empty()
                status_placeholder.empty()
        else:
            progress_bar.progress(100, text="âŒ ë¼ë²¨ íŒŒì¼ì´ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±")
            status_placeholder.warning("ğŸ“ profile.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            time.sleep(1)
            
            progress_bar.empty()
            status_placeholder.empty()
    else:
        # ì§„í–‰ ìƒí™© í‘œì‹œ ì—†ì´ ë¡œë“œ
        if os.path.exists(profile_path):
            try:
                labels = pd.read_csv(profile_path, sep='\t', header=None,
                                   names=['cooler', 'valve', 'pump', 'hydraulic', 'stable'])
                return labels
            except Exception as e:
                st.warning(f"ë¼ë²¨ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë°ì´í„° ìƒì„±
    return generate_dummy_labels()

@st.cache_resource(ttl=3600)  # 1ì‹œê°„ ë™ì•ˆ ìºì‹œ
def load_models(model_folder_path='models', show_progress=True):
    """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ (ìºì‹œë¨)"""
    models = None
    scalers = None
    metadata = None
    
    if show_progress:
        progress_text = "ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."
        progress_bar = st.progress(0, text=progress_text)
        status_placeholder = st.empty()
        
        # í•„ìš”í•œ íŒŒì¼ë“¤
        required_files = {
            'models.pkl': 'ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸',
            'scalers.pkl': 'ë°ì´í„° ìŠ¤ì¼€ì¼ëŸ¬',
            'metadata.json': 'ëª¨ë¸ ë©”íƒ€ë°ì´í„°'
        }
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        missing_files = []
        for filename, description in required_files.items():
            file_path = os.path.join(model_folder_path, filename)
            if not os.path.exists(file_path):
                missing_files.append(f"{filename} ({description})")
        
        if missing_files:
            progress_bar.progress(100, text="âŒ í•„ìš”í•œ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            status_placeholder.error(f"âŒ ë‹¤ìŒ íŒŒì¼ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_files)}")
            time.sleep(2)
            progress_bar.empty()
            status_placeholder.empty()
            return None, None, None
        
        try:
            # models.pkl ë¡œë“œ
            progress_bar.progress(10, text="ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì¤‘...")
            status_placeholder.info("ğŸ”„ models.pkl íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
            time.sleep(0.2)
            
            model_path = os.path.join(model_folder_path, 'models.pkl')
            with open(model_path, 'rb') as f:
                models = pickle.load(f)
            
            progress_bar.progress(40, text="âœ… ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            status_placeholder.success(f"âœ… ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ({len(models)} ëª¨ë¸)")
            time.sleep(0.3)

            # scalers.pkl ë¡œë“œ
            progress_bar.progress(50, text="ğŸ“ ë°ì´í„° ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ ë¡œë“œ ì¤‘...")
            status_placeholder.info("ğŸ”„ scalers.pkl íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
            time.sleep(0.2)
            
            scaler_path = os.path.join(model_folder_path, 'scalers.pkl')
            with open(scaler_path, 'rb') as f:
                scalers = pickle.load(f)
            
            progress_bar.progress(70, text="âœ… ë°ì´í„° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
            status_placeholder.success(f"âœ… ë°ì´í„° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ! ({len(scalers)} ìŠ¤ì¼€ì¼ëŸ¬)")
            time.sleep(0.3)

            # metadata.json ë¡œë“œ
            progress_bar.progress(80, text="ğŸ“‹ ëª¨ë¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ ë¡œë“œ ì¤‘...")
            status_placeholder.info("ğŸ”„ metadata.json íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
            time.sleep(0.2)
            
            metadata_path = os.path.join(model_folder_path, 'metadata.json')
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            progress_bar.progress(90, text="âœ… ëª¨ë¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            status_placeholder.success(f"âœ… ëª¨ë¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ({len(metadata)} í•­ëª©)")
            time.sleep(0.3)

            progress_bar.progress(100, text="ğŸ‰ ëª¨ë“  ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì™„ë£Œ!")
            status_placeholder.success("ğŸ‰ ëª¨ë“  ëª¨ë¸ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            time.sleep(1)
            
            progress_bar.empty()
            status_placeholder.empty()
            
            return models, scalers, metadata
            
        except FileNotFoundError as e:
            progress_bar.progress(100, text="âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            status_placeholder.error(f"âŒ í•„ìš”í•œ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {e}")
            status_placeholder.info("ğŸ’¡ train_model.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ì €ì¥í•˜ì„¸ìš”.")
            time.sleep(2)
            progress_bar.empty()
            status_placeholder.empty()
            return None, None, None
        except Exception as e:
            progress_bar.progress(100, text="âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            status_placeholder.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            time.sleep(2)
            progress_bar.empty()
            status_placeholder.empty()
            return None, None, None
    else:
        # ì§„í–‰ ìƒí™© í‘œì‹œ ì—†ì´ ë¡œë“œ (ê¸°ì¡´ ë°©ì‹)
        try:
            # models.pkl ë¡œë“œ
            model_path = os.path.join(model_folder_path, 'models.pkl')
            if os.path.exists(model_path):
                with open(model_path, 'rb') as f:
                    models = pickle.load(f)
            else:
                return None, None, None

            # scalers.pkl ë¡œë“œ
            scaler_path = os.path.join(model_folder_path, 'scalers.pkl')
            if os.path.exists(scaler_path):
                with open(scaler_path, 'rb') as f:
                    scalers = pickle.load(f)
            else:
                return None, None, None

            # metadata.json ë¡œë“œ
            metadata_path = os.path.join(model_folder_path, 'metadata.json')
            if os.path.exists(metadata_path):
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)

            return models, scalers, metadata
            
        except Exception as e:
            st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, None, None

def generate_dummy_sensor_data():
    """ë”ë¯¸ ì„¼ì„œ ë°ì´í„° ìƒì„±"""
    sensor_list = ['PS1', 'PS2', 'PS3', 'PS4', 'PS5', 'PS6', 'EPS1']
    sensor_data = {}
    
    for sensor in sensor_list:
        # 100ê°œ ì‚¬ì´í´, ê° ì‚¬ì´í´ë‹¹ 6000ê°œ ë°ì´í„° í¬ì¸íŠ¸ (60ì´ˆ * 100Hz)
        num_cycles = 100
        cycle_length = 6000
        
        # ì„¼ì„œ íƒ€ì…ë³„ ê¸°ë³¸ê°’ ì„¤ì •
        if sensor.startswith('PS'):
            base_value = np.random.uniform(140, 160)
        elif sensor == 'EPS1':
            base_value = np.random.uniform(2000, 2500)
        else:
            base_value = np.random.uniform(35, 40)
        
        # ì‚¬ì´í´ë³„ ë°ì´í„° ìƒì„±
        dummy_data = []
        for cycle in range(num_cycles):
            cycle_data = base_value + np.random.normal(0, base_value * 0.03, cycle_length)
            dummy_data.append(cycle_data)
        
        sensor_data[sensor] = pd.DataFrame(dummy_data)
    
    return sensor_data

def generate_dummy_labels():
    """ë”ë¯¸ ë¼ë²¨ ë°ì´í„° ìƒì„±"""
    num_cycles = 100
    
    labels = pd.DataFrame({
        'cooler': np.random.choice([3, 20, 100], num_cycles, p=[0.1, 0.2, 0.7]),
        'valve': np.random.choice([73, 80, 90, 100], num_cycles, p=[0.1, 0.1, 0.2, 0.6]),
        'pump': np.random.choice([0, 1, 2], num_cycles, p=[0.7, 0.2, 0.1]),
        'hydraulic': np.random.choice([90, 100, 115, 130], num_cycles, p=[0.1, 0.1, 0.2, 0.6]),
        'stable': np.ones(num_cycles, dtype=int)
    })
    
    return labels

# íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
def extract_features_from_window(window_data):
    """ìœˆë„ìš° ë°ì´í„°ì—ì„œ íŠ¹ì§• ì¶”ì¶œ (NaN ì²˜ë¦¬ ê°•í™”)"""
    features = {}
    
    for sensor_name, sensor_values in window_data.items():
        values = np.array(sensor_values)
        
        # ìœ íš¨í•œ ê°’ë§Œ ì„ íƒ (NaN, inf ì œê±°)
        valid_values = values[np.isfinite(values)]
        
        if len(valid_values) < 2:
            # ìœ íš¨í•œ ê°’ì´ ë¶€ì¡±í•œ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
            features[f'{sensor_name}_mean'] = 0.0
            features[f'{sensor_name}_std'] = 0.0
            features[f'{sensor_name}_max'] = 0.0
            features[f'{sensor_name}_min'] = 0.0
            features[f'{sensor_name}_rms'] = 0.0
            features[f'{sensor_name}_peak2peak'] = 0.0
            features[f'{sensor_name}_skew'] = 0.0
            features[f'{sensor_name}_kurtosis'] = 0.0
            continue
        
        # ê¸°ë³¸ í†µê³„ íŠ¹ì§•
        try:
            features[f'{sensor_name}_mean'] = np.mean(valid_values)
        except:
            features[f'{sensor_name}_mean'] = 0.0
            
        try:
            features[f'{sensor_name}_std'] = np.std(valid_values)
        except:
            features[f'{sensor_name}_std'] = 0.0
            
        try:
            features[f'{sensor_name}_max'] = np.max(valid_values)
        except:
            features[f'{sensor_name}_max'] = 0.0
            
        try:
            features[f'{sensor_name}_min'] = np.min(valid_values)
        except:
            features[f'{sensor_name}_min'] = 0.0
            
        try:
            features[f'{sensor_name}_rms'] = np.sqrt(np.mean(valid_values**2))
        except:
            features[f'{sensor_name}_rms'] = 0.0
            
        try:
            features[f'{sensor_name}_peak2peak'] = np.max(valid_values) - np.min(valid_values)
        except:
            features[f'{sensor_name}_peak2peak'] = 0.0
            
        # ê³ ì°¨ í†µê³„ íŠ¹ì§•
        try:
            if len(valid_values) > 2:
                skew_val = skew(valid_values)
                features[f'{sensor_name}_skew'] = skew_val if np.isfinite(skew_val) else 0.0
            else:
                features[f'{sensor_name}_skew'] = 0.0
        except:
            features[f'{sensor_name}_skew'] = 0.0
            
        try:
            if len(valid_values) > 2:
                kurt_val = kurtosis(valid_values)
                features[f'{sensor_name}_kurtosis'] = kurt_val if np.isfinite(kurt_val) else 0.0
            else:
                features[f'{sensor_name}_kurtosis'] = 0.0
        except:
            features[f'{sensor_name}_kurtosis'] = 0.0
    
    return features

# ì´ìƒ íƒì§€ í•¨ìˆ˜
def detect_anomaly(features, models, scalers, metadata):
    """ê° ë¶€í’ˆë³„ ì´ìƒ íƒì§€ (NaN ì²˜ë¦¬ ê°•í™”)"""
    # DataFrame ìƒì„±
    features_df = pd.DataFrame([features])
    
    # metadataì—ì„œ feature_columns ê°€ì ¸ì˜¤ê¸°
    feature_cols = metadata.get('feature_columns', [])
    
    # í•„ìš”í•œ íŠ¹ì§•ë§Œ ì„ íƒí•˜ê³  ëˆ„ë½ëœ íŠ¹ì§•ì€ 0ìœ¼ë¡œ ì±„ì›€
    features_selected = features_df.reindex(columns=feature_cols, fill_value=0.0)
    
    # NaN ê°’ì„ 0ìœ¼ë¡œ ëŒ€ì²´
    features_selected = features_selected.fillna(0.0)
    
    # inf ê°’ë„ ì²˜ë¦¬
    features_selected = features_selected.replace([np.inf, -np.inf], 0.0)
    
    # ìµœì¢… ê²€ì¦: ì—¬ì „íˆ NaNì´ ìˆëŠ”ì§€ í™•ì¸
    if features_selected.isnull().any().any():
        st.warning("íŠ¹ì§• ë°ì´í„°ì— ì—¬ì „íˆ NaN ê°’ì´ ìˆìŠµë‹ˆë‹¤. ëª¨ë“  NaNì„ 0ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        features_selected = features_selected.fillna(0.0)
    
    results = {}
    
    for comp_name in ['cooler', 'valve', 'pump', 'hydraulic']:
        try:
            # ìŠ¤ì¼€ì¼ë§ ì „ ë°ì´í„° ê²€ì¦
            X_input = features_selected.copy()
            
            # ìŠ¤ì¼€ì¼ë§
            X_scaled = scalers[comp_name].transform(X_input)
            
            # ìŠ¤ì¼€ì¼ë§ í›„ì—ë„ NaN ì²´í¬
            if np.any(np.isnan(X_scaled)) or np.any(np.isinf(X_scaled)):
                st.warning(f"{comp_name} ìŠ¤ì¼€ì¼ë§ í›„ NaN/inf ê°’ ë°œê²¬. 0ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0)
            
            # ì˜ˆì¸¡
            prediction = models[comp_name].predict(X_scaled)[0]
            score = models[comp_name].decision_function(X_scaled)[0]
            
            # ì ìˆ˜ê°€ NaNì¸ ê²½ìš° ì²˜ë¦¬
            if np.isnan(score) or np.isinf(score):
                score = 0.0
            
            results[comp_name] = {
                'is_anomaly': prediction == -1,
                'score': float(score),
                'confidence': abs(float(score))
            }
            
        except Exception as e:
            st.error(f"{comp_name} ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
            results[comp_name] = {
                'is_anomaly': False,
                'score': 0.0,
                'confidence': 0.0
            }
    
    return results

# ë°ì´í„° ë¡œë” ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ìºì‹œë¨)
@st.cache_resource(ttl=3600)
def get_data_loader(data_folder_path='data'):
    """ë°ì´í„° ë¡œë” ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ìºì‹œë¨)"""
    loader = HydraulicDataLoader(data_folder_path)
    loader._load_all_data()
    return loader