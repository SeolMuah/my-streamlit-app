import streamlit as st
import pandas as pd
import numpy as np
import pickle
import json
import os
import time
from scipy.stats import skew, kurtosis
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# ìƒìˆ˜ ì •ì˜
# =============================================================================
MAX_ROWS = 100 #ë°ì´í„° 100ê°œ í–‰ë§Œ ì½ë„ë¡ í•¨ (ì„¼ì„œ ë° ë¼ë²¨)

# ì„¼ì„œë³„ ì£¼íŒŒìˆ˜ ì •ë³´ (Hz)
SENSOR_FREQUENCIES = {
    'PS1': 100, 'PS2': 100, 'PS3': 100, 'PS4': 100, 'PS5': 100, 'PS6': 100,
    'EPS1': 100,
    'FS1': 10, 'FS2': 10,
    'TS1': 1, 'TS2': 1, 'TS3': 1, 'TS4': 1,
    'VS1': 1,
    'CE': 1, 'CP': 1, 'SE': 1
}

# ì„¼ì„œë³„ ìƒì„¸ ì •ë³´
SENSOR_INFO = {
    'PS1': {'freq': 100, 'type': 'pressure', 'unit': 'bar', 'range': (140, 160)},
    'PS2': {'freq': 100, 'type': 'pressure', 'unit': 'bar', 'range': (140, 160)},
    'PS3': {'freq': 100, 'type': 'pressure', 'unit': 'bar', 'range': (140, 160)},
    'PS4': {'freq': 100, 'type': 'pressure', 'unit': 'bar', 'range': (140, 160)},
    'PS5': {'freq': 100, 'type': 'pressure', 'unit': 'bar', 'range': (140, 160)},
    'PS6': {'freq': 100, 'type': 'pressure', 'unit': 'bar', 'range': (140, 160)},
    'EPS1': {'freq': 100, 'type': 'motor_power', 'unit': 'W', 'range': (2000, 2500)},
    'FS1': {'freq': 10, 'type': 'flow', 'unit': 'L/min', 'range': (8, 12)},
    'FS2': {'freq': 10, 'type': 'flow', 'unit': 'L/min', 'range': (8, 12)},
    'TS1': {'freq': 1, 'type': 'temperature', 'unit': 'Â°C', 'range': (35, 40)},
    'TS2': {'freq': 1, 'type': 'temperature', 'unit': 'Â°C', 'range': (35, 40)},
    'TS3': {'freq': 1, 'type': 'temperature', 'unit': 'Â°C', 'range': (35, 40)},
    'TS4': {'freq': 1, 'type': 'temperature', 'unit': 'Â°C', 'range': (35, 40)},
    'VS1': {'freq': 1, 'type': 'vibration', 'unit': 'mm/s', 'range': (0.5, 1.0)},
    'CE': {'freq': 1, 'type': 'cooling_efficiency', 'unit': '%', 'range': (0.8, 1.2)},
    'CP': {'freq': 1, 'type': 'cooling_power', 'unit': 'kW', 'range': (0.8, 1.2)},
    'SE': {'freq': 1, 'type': 'efficiency_factor', 'unit': '%', 'range': (0.8, 1.2)}
}

# ë¶€í’ˆë³„ ìƒíƒœ ì •ì˜
COMPONENT_STATES = {
    'cooler': {3: 'close_to_failure', 20: 'reduced_efficiency', 100: 'full_efficiency'},
    'valve': {73: 'optimal_switching', 80: 'small_lag', 90: 'severe_lag', 100: 'close_to_failure'},
    'pump': {0: 'no_leakage', 1: 'weak_leakage', 2: 'severe_leakage'},
    'hydraulic': {90: 'close_to_failure', 100: 'optimal_pressure', 115: 'slightly_reduced', 130: 'severely_reduced'}
}

# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================

def get_sensor_time_axis(sensor_name, cycle_duration=60):
    """ì„¼ì„œë³„ ì‹œê°„ì¶• ìƒì„±"""
    freq = SENSOR_FREQUENCIES.get(sensor_name, 1)
    num_samples = freq * cycle_duration
    return np.linspace(0, cycle_duration, num_samples)

def safe_calculate_feature(values, feature_func, default_value=0.0):
    """ì•ˆì „í•œ íŠ¹ì§• ê³„ì‚° (NaN ì²˜ë¦¬)"""
    try:
        if len(values) < 2:
            return default_value
        result = feature_func(values)
        return result if np.isfinite(result) else default_value
    except Exception:
        return default_value

def generate_dummy_cycle_data(sensor_name, cycle_length):
    """ì„¼ì„œë³„ ë”ë¯¸ ì‚¬ì´í´ ë°ì´í„° ìƒì„±"""
    sensor_info = SENSOR_INFO.get(sensor_name, {'range': (0, 1)})
    base_value = np.random.uniform(*sensor_info['range'])
    noise_level = base_value * 0.03
    return base_value + np.random.normal(0, noise_level, cycle_length)

# =============================================================================
# ë°ì´í„° ë¡œë” í´ë˜ìŠ¤
# =============================================================================

class HydraulicDataLoader:
    """ìœ ì•• ì‹œìŠ¤í…œ ë°ì´í„° ë¡œë”"""
    
    def __init__(self, data_folder_path='data', window_seconds=10, stride_seconds=10):
        self.data_folder_path = data_folder_path
        self.window_seconds = window_seconds
        self.stride_seconds = stride_seconds
        self.sensor_data = {}
        self.profile_data = None
        self.current_cycle_index = 0
        self.num_cycles = 0
        self.is_dummy_data = False

    def _load_all_data(self):
        """ëª¨ë“  ì„¼ì„œ ë°ì´í„°ì™€ í”„ë¡œíŒŒì¼ ë¡œë“œ"""
        if not os.path.exists(self.data_folder_path):
            st.warning(f"ë°ì´í„° í´ë” '{self.data_folder_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self._generate_dummy_data()
            return

        try:
            with st.spinner("ë°ì´í„° ë¡œë“œ ì¤‘..."):
                self._load_sensor_files()
                self._load_profile_file()
                
                if not self.sensor_data:
                    self._generate_dummy_data()
                    st.warning("ì‹¤ì œ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                else:
                    st.success(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ì´ {self.num_cycles}ê°œ ì‚¬ì´í´")
                    
        except Exception as e:
            st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self._generate_dummy_data()

    def _load_sensor_files(self):
        """ì„¼ì„œ íŒŒì¼ë“¤ ë¡œë“œ"""
        sensor_names = list(SENSOR_INFO.keys())
        progress_bar = st.progress(0, text="ì„¼ì„œ ë°ì´í„° íŒŒì¼ ì½ëŠ” ì¤‘...")
        
        for i, sensor_name in enumerate(sensor_names):
            file_path = os.path.join(self.data_folder_path, f"{sensor_name}.txt")
            progress_bar.progress(
                int(((i + 1) / len(sensor_names)) * 80), 
                text=f"{sensor_name}.txt ë¡œë“œ ì¤‘..."
            )
            
            if os.path.exists(file_path):
                try:
                    data = pd.read_csv(file_path, sep='\t', header=None)
                    self.sensor_data[sensor_name] = data
                except Exception as e:
                    st.warning(f"ì„¼ì„œ '{sensor_name}' íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            else:
                st.warning(f"ì„¼ì„œ '{sensor_name}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        progress_bar.empty()

    def _load_profile_file(self):
        """í”„ë¡œíŒŒì¼ íŒŒì¼ ë¡œë“œ"""
        profile_path = os.path.join(self.data_folder_path, 'profile.txt')
        
        if os.path.exists(profile_path):
            try:
                self.profile_data = pd.read_csv(
                    profile_path, 
                    sep='\t', 
                    header=None,
                    names=['cooler', 'valve', 'pump', 'hydraulic', 'stable']
                )
                self.num_cycles = len(self.profile_data)
            except Exception as e:
                st.warning(f"í”„ë¡œíŒŒì¼ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            st.warning("í”„ë¡œíŒŒì¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def _generate_dummy_data(self):
        """ë”ë¯¸ ë°ì´í„° ìƒì„±"""
        self.num_cycles = 100
        self.is_dummy_data = True
        
        # ì„¼ì„œ ë°ì´í„° ìƒì„±
        for sensor_name, info in SENSOR_INFO.items():
            freq = info['freq']
            cycle_length = freq * 60  # 60ì´ˆ ì‚¬ì´í´
            
            dummy_data = []
            for cycle in range(self.num_cycles):
                cycle_data = generate_dummy_cycle_data(sensor_name, cycle_length)
                dummy_data.append(cycle_data)
            
            self.sensor_data[sensor_name] = pd.DataFrame(dummy_data)
        
        # í”„ë¡œíŒŒì¼ ë°ì´í„° ìƒì„±
        self.profile_data = pd.DataFrame({
            'cooler': np.random.choice([3, 20, 100], self.num_cycles, p=[0.1, 0.2, 0.7]),
            'valve': np.random.choice([73, 80, 90, 100], self.num_cycles, p=[0.1, 0.1, 0.2, 0.6]),
            'pump': np.random.choice([0, 1, 2], self.num_cycles, p=[0.7, 0.2, 0.1]),
            'hydraulic': np.random.choice([90, 100, 115, 130], self.num_cycles, p=[0.1, 0.1, 0.2, 0.6]),
            'stable': np.ones(self.num_cycles, dtype=int)
        })

    def get_next_window(self):
        """ë‹¤ìŒ 10ì´ˆ ìœˆë„ìš° ë°ì´í„° ë°˜í™˜"""
        if self.num_cycles == 0:
            return None, None
        
        # ì‚¬ì´í´ ì¸ë±ìŠ¤ ìˆœí™˜
        if self.current_cycle_index >= self.num_cycles:
            self.current_cycle_index = 0
        
        cycle_idx = self.current_cycle_index
        window_start = np.random.choice([0, 10, 20, 30, 40, 50])  # ëœë¤ ì‹œì‘ ìœ„ì¹˜
        window_end = window_start + self.window_seconds
        
        window_data = {}
        
        # ê° ì„¼ì„œì˜ ìœˆë„ìš° ë°ì´í„° ì¶”ì¶œ
        for sensor_name, sensor_df in self.sensor_data.items():
            freq = SENSOR_INFO[sensor_name]['freq']
            start_idx = int(window_start * freq)
            end_idx = int(window_end * freq)
            
            cycle_data = sensor_df.iloc[cycle_idx].values
            window_data[sensor_name] = cycle_data[start_idx:end_idx]
        
        # ë¼ë²¨ ì •ë³´
        cycle_labels = self.profile_data.iloc[cycle_idx] if self.profile_data is not None else None
        
        self.current_cycle_index += 1
        return window_data, cycle_labels

# =============================================================================
# íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
# =============================================================================

def extract_features_from_window(window_data):
    """ìœˆë„ìš° ë°ì´í„°ì—ì„œ íŠ¹ì§• ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
    features = {}
    
    for sensor_name, sensor_values in window_data.items():
        values = np.array(sensor_values)
        
        # ìœ íš¨í•œ ê°’ë§Œ ì„ íƒ
        valid_values = values[np.isfinite(values)]
        
        if len(valid_values) < 2:
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
            feature_defaults = {
                'mean': 0.0, 'std': 0.0, 'max': 0.0, 'min': 0.0,
                'rms': 0.0, 'peak2peak': 0.0, 'skew': 0.0, 'kurtosis': 0.0
            }
            for feature_name, default_val in feature_defaults.items():
                features[f'{sensor_name}_{feature_name}'] = default_val
            continue
        
        # ê¸°ë³¸ í†µê³„ íŠ¹ì§•
        features[f'{sensor_name}_mean'] = safe_calculate_feature(valid_values, np.mean)
        features[f'{sensor_name}_std'] = safe_calculate_feature(valid_values, np.std)
        features[f'{sensor_name}_max'] = safe_calculate_feature(valid_values, np.max)
        features[f'{sensor_name}_min'] = safe_calculate_feature(valid_values, np.min)
        features[f'{sensor_name}_rms'] = safe_calculate_feature(
            valid_values, lambda x: np.sqrt(np.mean(x**2))
        )
        features[f'{sensor_name}_peak2peak'] = safe_calculate_feature(
            valid_values, lambda x: np.max(x) - np.min(x)
        )
        
        # ê³ ì°¨ í†µê³„ íŠ¹ì§•
        if len(valid_values) > 2:
            features[f'{sensor_name}_skew'] = safe_calculate_feature(valid_values, skew)
            features[f'{sensor_name}_kurtosis'] = safe_calculate_feature(valid_values, kurtosis)
        else:
            features[f'{sensor_name}_skew'] = 0.0
            features[f'{sensor_name}_kurtosis'] = 0.0
    
    return features

# =============================================================================
# ì´ìƒ íƒì§€ í•¨ìˆ˜
# =============================================================================

def detect_anomaly(features, models, scalers, metadata):
    """ê° ë¶€í’ˆë³„ ì´ìƒ íƒì§€ (ê°œì„ ëœ ë²„ì „)"""
    # íŠ¹ì§• DataFrame ìƒì„±
    features_df = pd.DataFrame([features])
    
    # ë©”íƒ€ë°ì´í„°ì—ì„œ íŠ¹ì§• ì»¬ëŸ¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    feature_cols = metadata.get('feature_columns', [])
    
    # í•„ìš”í•œ íŠ¹ì§•ë§Œ ì„ íƒí•˜ê³  ëˆ„ë½ëœ íŠ¹ì§•ì€ 0ìœ¼ë¡œ ì±„ì›€
    features_selected = features_df.reindex(columns=feature_cols, fill_value=0.0)
    
    # NaN ë° inf ê°’ ì²˜ë¦¬
    features_selected = features_selected.fillna(0.0)
    features_selected = features_selected.replace([np.inf, -np.inf], 0.0)
    
    results = {}
    
    for comp_name in ['cooler', 'valve', 'pump', 'hydraulic']:
        try:
            # ìŠ¤ì¼€ì¼ë§
            X_scaled = scalers[comp_name].transform(features_selected)
            
            # ìŠ¤ì¼€ì¼ë§ í›„ NaN/inf ì²˜ë¦¬
            X_scaled = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0)
            
            # ì˜ˆì¸¡
            prediction = models[comp_name].predict(X_scaled)[0]
            score = models[comp_name].decision_function(X_scaled)[0]
            
            # ì ìˆ˜ ê²€ì¦
            if not np.isfinite(score):
                score = 0.0
            
            results[comp_name] = {
                'is_anomaly': prediction == -1,
                'score': float(score),
                'confidence': abs(float(score))
            }
            
        except Exception as e:
            st.error(f"{comp_name} ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            results[comp_name] = {
                'is_anomaly': False,
                'score': 0.0,
                'confidence': 0.0
            }
    
    return results

# =============================================================================
# ë”ë¯¸ ë°ì´í„° ìƒì„± í•¨ìˆ˜
# =============================================================================

def generate_dummy_sensor_data():
    """ë”ë¯¸ ì„¼ì„œ ë°ì´í„° ìƒì„± (ìºì‹œìš©)"""
    sensor_data = {}
    num_cycles = 100
    
    for sensor_name, info in SENSOR_INFO.items():
        freq = info['freq']
        cycle_length = freq * 60  # 60ì´ˆ ì‚¬ì´í´
        
        dummy_data = []
        for cycle in range(num_cycles):
            cycle_data = generate_dummy_cycle_data(sensor_name, cycle_length)
            dummy_data.append(cycle_data)
        
        sensor_data[sensor_name] = pd.DataFrame(dummy_data)
    
    return sensor_data

def generate_dummy_labels():
    """ë”ë¯¸ ë¼ë²¨ ë°ì´í„° ìƒì„± (ìºì‹œìš©)"""
    num_cycles = 100
    
    return pd.DataFrame({
        'cooler': np.random.choice([3, 20, 100], num_cycles, p=[0.1, 0.2, 0.7]),
        'valve': np.random.choice([73, 80, 90, 100], num_cycles, p=[0.1, 0.1, 0.2, 0.6]),
        'pump': np.random.choice([0, 1, 2], num_cycles, p=[0.7, 0.2, 0.1]),
        'hydraulic': np.random.choice([90, 100, 115, 130], num_cycles, p=[0.1, 0.1, 0.2, 0.6]),
        'stable': np.ones(num_cycles, dtype=int)
    })

# =============================================================================
# ìºì‹œëœ ë°ì´í„° ë¡œë” í•¨ìˆ˜ë“¤
# =============================================================================

@st.cache_resource(ttl=3600)
def get_data_loader(data_folder_path='data'):
    """ë°ì´í„° ë¡œë” ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ìºì‹œë¨)"""
    loader = HydraulicDataLoader(data_folder_path)
    loader._load_all_data()
    return loader

@st.cache_data(ttl=3600)
def load_sensor_data(data_folder_path='data', show_progress=True):
    """ì„¼ì„œ ë°ì´í„° ë¡œë“œ (ìºì‹œë¨)"""
    sensor_list = list(SENSOR_INFO.keys())
    sensor_data = {}
    
    if show_progress:
        progress_bar = st.progress(0, text="ì„¼ì„œ ë°ì´í„° íŒŒì¼ì„ í™•ì¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
        status_placeholder = st.empty()
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        existing_files = [
            sensor for sensor in sensor_list 
            if os.path.exists(os.path.join(data_folder_path, f'{sensor}.txt'))
        ]
        
        if not existing_files:
            progress_bar.progress(100, text="ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            status_placeholder.warning("ğŸ“ ì‹¤ì œ ì„¼ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            time.sleep(1)
            sensor_data = generate_dummy_sensor_data()
            progress_bar.empty()
            status_placeholder.empty()
            return sensor_data
        
        # íŒŒì¼ ë¡œë”©
        for i, sensor in enumerate(existing_files):
            file_path = os.path.join(data_folder_path, f'{sensor}.txt')
            progress_percent = int((i / len(existing_files)) * 100)
            progress_bar.progress(progress_percent, text=f"ğŸ“Š {sensor}.txt íŒŒì¼ ë¡œë”© ì¤‘... ({i+1}/{len(existing_files)})")
            
            try:
                status_placeholder.info(f"ğŸ”„ {sensor}.txt íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
                data = pd.read_csv(file_path, sep='\t', header=None, nrows=MAX_ROWS)
                sensor_data[sensor] = data
                status_placeholder.success(f"âœ… {sensor}.txt íŒŒì¼ ë¡œë“œ ì™„ë£Œ! ({len(data)} í–‰)")
                time.sleep(0.1)
            except Exception as e:
                status_placeholder.error(f"âŒ {sensor}.txt íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                time.sleep(0.5)
        
        progress_bar.progress(100, text=f"âœ… ì„¼ì„œ ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
        
        if not sensor_data:
            status_placeholder.warning("ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            sensor_data = generate_dummy_sensor_data()
        else:
            status_placeholder.success(f"ğŸ‰ ì´ {len(sensor_data)}ê°œì˜ ì„¼ì„œ ë°ì´í„° íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        time.sleep(1)
        progress_bar.empty()
        status_placeholder.empty()
    else:
        # ì§„í–‰ ìƒí™© í‘œì‹œ ì—†ì´ ë¡œë“œ
        for sensor in sensor_list:
            file_path = os.path.join(data_folder_path, f'{sensor}.txt')
            if os.path.exists(file_path):
                try:
                    data = pd.read_csv(file_path, sep='\t', header=None, nrows=MAX_ROWS)
                    sensor_data[sensor] = data
                except Exception as e:
                    st.warning(f"ì„¼ì„œ {sensor} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        if not sensor_data:
            sensor_data = generate_dummy_sensor_data()
    
    return sensor_data

@st.cache_data(ttl=3600)
def load_labels(data_folder_path='data', show_progress=True):
    """ë¼ë²¨ ë°ì´í„° ë¡œë“œ (ìºì‹œë¨)"""
    profile_path = os.path.join(data_folder_path, 'profile.txt')
    
    if show_progress:
        progress_bar = st.progress(0, text="ë¼ë²¨ ë°ì´í„° íŒŒì¼ì„ í™•ì¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
        status_placeholder = st.empty()
        
        if os.path.exists(profile_path):
            try:
                progress_bar.progress(50, text="ğŸ“‹ profile.txt íŒŒì¼ ì½ëŠ” ì¤‘...")
                status_placeholder.info("ğŸ”„ profile.txt íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
                
                labels = pd.read_csv(profile_path, sep='\t', header=None,
                                   names=['cooler', 'valve', 'pump', 'hydraulic', 'stable'])
                
                progress_bar.progress(100, text="âœ… ë¼ë²¨ ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
                status_placeholder.success(f"âœ… profile.txt íŒŒì¼ ë¡œë“œ ì™„ë£Œ! ({len(labels)} ë¼ë²¨)")
                
                time.sleep(0.5)
                progress_bar.empty()
                status_placeholder.empty()
                return labels
                
            except Exception as e:
                progress_bar.progress(100, text="âŒ ë¼ë²¨ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
                status_placeholder.error(f"âŒ profile.txt íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                time.sleep(1)
                progress_bar.empty()
                status_placeholder.empty()
        else:
            progress_bar.progress(100, text="ì‹œë®¬ë ˆì´ì…˜ ë¼ë²¨ ë°ì´í„° ìƒì„±")
            status_placeholder.warning("ğŸ“ profile.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            time.sleep(1)
            progress_bar.empty()
            status_placeholder.empty()
    else:
        # ì§„í–‰ ìƒí™© í‘œì‹œ ì—†ì´ ë¡œë“œ
        if os.path.exists(profile_path):
            try:
                labels = pd.read_csv(profile_path, sep='\t', header=None,
                                   names=['cooler', 'valve', 'pump', 'hydraulic', 'stable'], nrows=MAX_ROWS)
                return labels
            except Exception as e:
                st.warning(f"ë¼ë²¨ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return generate_dummy_labels()

@st.cache_resource(ttl=3600)
def load_models(model_folder_path='models', show_progress=True):
    """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ (ìºì‹œë¨)"""
    required_files = {
        'models.pkl': 'ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸',
        'scalers.pkl': 'ë°ì´í„° ìŠ¤ì¼€ì¼ëŸ¬',
        'metadata.json': 'ëª¨ë¸ ë©”íƒ€ë°ì´í„°'
    }
    
    if show_progress:
        progress_bar = st.progress(0, text="ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
        status_placeholder = st.empty()
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        missing_files = []
        for filename, description in required_files.items():
            file_path = os.path.join(model_folder_path, filename)
            if not os.path.exists(file_path):
                missing_files.append(f"{filename} ({description})")
        
        if missing_files:
            progress_bar.progress(100, text="âŒ í•„ìš”í•œ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            status_placeholder.error(f"âŒ ë‹¤ìŒ íŒŒì¼ë“¤ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_files)}")
            time.sleep(2)
            progress_bar.empty()
            status_placeholder.empty()
            return None, None, None
        
        try:
            models, scalers, metadata = None, None, None
            
            # ëª¨ë¸ ë¡œë“œ
            progress_bar.progress(30, text="ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            status_placeholder.info("ğŸ”„ models.pkl íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
            with open(os.path.join(model_folder_path, 'models.pkl'), 'rb') as f:
                models = pickle.load(f)
            status_placeholder.success(f"âœ… ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ({len(models)} ëª¨ë¸)")
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            progress_bar.progress(60, text="ğŸ“ ë°ì´í„° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì¤‘...")
            status_placeholder.info("ğŸ”„ scalers.pkl íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
            with open(os.path.join(model_folder_path, 'scalers.pkl'), 'rb') as f:
                scalers = pickle.load(f)
            status_placeholder.success(f"âœ… ë°ì´í„° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ! ({len(scalers)} ìŠ¤ì¼€ì¼ëŸ¬)")
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            progress_bar.progress(90, text="ğŸ“‹ ëª¨ë¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì¤‘...")
            status_placeholder.info("ğŸ”„ metadata.json íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
            with open(os.path.join(model_folder_path, 'metadata.json'), 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            status_placeholder.success(f"âœ… ëª¨ë¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
            
            progress_bar.progress(100, text="ğŸ‰ ëª¨ë“  ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì™„ë£Œ!")
            status_placeholder.success("ğŸ‰ ëª¨ë“  ëª¨ë¸ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            time.sleep(1)
            progress_bar.empty()
            status_placeholder.empty()
            
            return models, scalers, metadata
            
        except Exception as e:
            progress_bar.progress(100, text="âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
            status_placeholder.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            time.sleep(2)
            progress_bar.empty()
            status_placeholder.empty()
            return None, None, None
    else:
        # ì§„í–‰ ìƒí™© í‘œì‹œ ì—†ì´ ë¡œë“œ
        try:
            models, scalers, metadata = None, None, None
            
            # ê° íŒŒì¼ ë¡œë“œ
            for filename in required_files.keys():
                file_path = os.path.join(model_folder_path, filename)
                if not os.path.exists(file_path):
                    return None, None, None
            
            with open(os.path.join(model_folder_path, 'models.pkl'), 'rb') as f:
                models = pickle.load(f)
            with open(os.path.join(model_folder_path, 'scalers.pkl'), 'rb') as f:
                scalers = pickle.load(f)
            with open(os.path.join(model_folder_path, 'metadata.json'), 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            return models, scalers, metadata
            
        except Exception as e:
            st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, None, None